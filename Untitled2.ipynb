{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "cn_5vDLuzVG1",
        "nLYytiNd0h59",
        "vQO81a46u7Bm",
        "MsX5CicYveYN",
        "yDohK0XxvnHv",
        "O0SXBJeW8QAp",
        "UktXZk5H_m2p",
        "A9f1hmGVVjlT",
        "-8AgAnoChJ_5",
        "zDRNTgCUtxSy"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "K4r9hf1ZKAdR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "67Zz7jWXzJEs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Retinanet Model (FPN + Focal Loss)"
      ]
    },
    {
      "metadata": {
        "id": "Vth2fZNvy42-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation, Add\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,Reshape\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MK2mdPNSJ9-C",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PupRMzLHzoln",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "wlC6AilC7ivR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_image_size = [None,None,3]\n",
        "num_classes=10\n",
        "include_top= False #False= Mutiple enconding o/p, True:classification o/p\n",
        "Resnet_trainable = False\n",
        "pyramid_network_filters=256\n",
        "data_format='channels_last'\n",
        "regression_filter=256\n",
        "classification_filter=256\n",
        "prior_prob = 0.01\n",
        "class_specific_filter = False\n",
        "max_detections=10\n",
        "score_threshold=0.05\n",
        "iou_threshold=0.5\n",
        "parallel_iterations=None\n",
        "\n",
        "# sizes   = [32.0, 64.0, 128.0, 256.0, 512.0]\n",
        "# strides = [8.0, 16.0, 32.0, 64.0, 128.0]\n",
        "# ratios  = [0.5, 1.0, 2.0]\n",
        "# scales  = [2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]\n",
        "sizes   = np.array([32.0, 64.0, 128.0, 256.0, 512.0], keras.backend.floatx())\n",
        "strides = np.array([8.0, 16.0, 32.0, 64.0, 128.0], keras.backend.floatx())\n",
        "ratios  = np.array([0.5, 1, 2], keras.backend.floatx())\n",
        "scales  = np.array([2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)], keras.backend.floatx())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TsiBNAnE4_su",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_anchors = len(ratios) * len(scales)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hk-oWht0eAA6",
        "colab_type": "code",
        "outputId": "df47c97b-782c-428e-ab3b-a7fbfd672356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "num_anchors"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "cn_5vDLuzVG1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Resnet50 Model"
      ]
    },
    {
      "metadata": {
        "id": "xf-CWKarzaeu",
        "colab_type": "code",
        "outputId": "52028a53-8811-4ff3-b26f-918883399379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install keras-resnet\n",
        "import keras_resnet\n",
        "import keras_resnet.models\n",
        "\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-resnet in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-resnet) (2.2.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-resnet) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-resnet) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-resnet) (1.14.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-resnet) (1.0.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-resnet) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-resnet) (1.0.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-resnet) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NbemX8k6uels",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "######Sub-level *testing* of resnet50"
      ]
    },
    {
      "metadata": {
        "id": "zis75EP8zh1t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def resnet50_model(input_image_size,num_classes,include_top ):\n",
        "#   x = keras.layers.Input(input_image_size)\n",
        "#   #print (x.output_shape)\n",
        "#   resnet50 = keras_resnet.models.ResNet50(x, classes=num_classes,include_top=include_top)\n",
        "  \n",
        "#   for layer in resnet50.layers:\n",
        "#     layer.trainable=Resnet_trainable\n",
        "    \n",
        "#   print(\"Trainable:-\",resnet50.layers[1].trainable)\n",
        "\n",
        "#   backbone_layers= resnet50.outputs[1:]\n",
        "#   print (\"\\n backbone_Layers[C3-C5]:-\",backbone_layers)\n",
        "  \n",
        "#   resnet50.summary()\n",
        "  \n",
        "#   return backbone_layers\n",
        "\n",
        "# bl=resnet50_model(input_image_size,num_classes,include_top)\n",
        "# bl #backbonelayers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sV3S1kTQWc7L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Har2CkX80e8q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Retinanet Model (Resnet50 as Backbone)"
      ]
    },
    {
      "metadata": {
        "id": "nLYytiNd0h59",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#####Feature Pyramid Network"
      ]
    },
    {
      "metadata": {
        "id": "xTEePBAB0i5f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Feature_Pyramid_Network(backbone_layers,pyramid_network_filters):\n",
        "  [C3,C4,C5]=backbone_layers\n",
        "  \n",
        "  C3_height   = K.shape(C3)[1]\n",
        "  C3_width    = K.shape(C3)[2]\n",
        "  C4_height   = K.shape(C4)[1]\n",
        "  C4_width    = K.shape(C4)[2]\n",
        "  \n",
        "  \n",
        "  P5          = Conv2D( kernel_size=1,   filters=pyramid_network_filters,   strides=1,   padding='same',   data_format=data_format) (C5)\n",
        "  P5_Upscale  = keras.layers.Lambda( lambda image1: tf.image.resize_images(P5, (C4_height,C4_width), method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)) (P5)\n",
        "  #P5_Upscale  = tf.image.resize_nearest_neighbor(P5,(C4_height,C4_width))\n",
        "  P5          = Conv2D( kernel_size=3,   filters=pyramid_network_filters,   strides=1,   padding='same',   data_format=data_format, name='P5') (P5)\n",
        "  \n",
        "  P4          = Conv2D( kernel_size=1,   filters=pyramid_network_filters,   strides=1,   padding='same',   data_format=data_format) (C4)\n",
        "  P4          = keras.layers.Add() ([P4,P5_Upscale])\n",
        "  P4_Upscale  = keras.layers.Lambda( lambda image2: tf.image.resize_images(P4, (C3_height,C3_width), method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)) (P4)\n",
        "  #P4_Upscale  = tf.image.resize_nearest_neighbor(P4,(C3_height,C3_width))\n",
        "  P4          = Conv2D( kernel_size=3,   filters=pyramid_network_filters,   strides=1,   padding='same',   data_format=data_format, name='P4') (P4)\n",
        "  \n",
        "  P3          = Conv2D( kernel_size=1,   filters=pyramid_network_filters,   strides=1,   padding='same',   data_format=data_format) (C3)\n",
        "  P3          = keras.layers.Add() ([P3,P4_Upscale])\n",
        "  P3          = Conv2D( kernel_size=3,   filters=pyramid_network_filters,   strides=1,   padding='same',   data_format=data_format, name='P3') (P3)\n",
        "  \n",
        "  P6          = Conv2D( kernel_size=3,   filters=pyramid_network_filters,   strides=2,   padding='same',   data_format=data_format, name='P6') (P5)\n",
        "  \n",
        "  P6_relu     = Activation('relu') (P6)\n",
        "  P7          = Conv2D( kernel_size=3,   filters=pyramid_network_filters,   strides=2,   padding='same',   data_format=data_format, name='P7') (P6_relu)\n",
        "  \n",
        "  \n",
        "  return [P3, P4, P5, P6, P7]\n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vQO81a46u7Bm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "######sub-level testing of feature pyramid network"
      ]
    },
    {
      "metadata": {
        "id": "RG4KsVUX0uX4",
        "colab_type": "code",
        "outputId": "e50515c5-549a-49d6-9737-d214960f6cd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "bl #backbonelayers\n",
        "g2=Feature_Pyramid_Network(backbone_layers= bl , pyramid_network_filters=pyramid_network_filters)\n",
        "g2\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'P3_2/BiasAdd:0' shape=(?, ?, ?, 256) dtype=float32>,\n",
              " <tf.Tensor 'P4_2/BiasAdd:0' shape=(?, ?, ?, 256) dtype=float32>,\n",
              " <tf.Tensor 'P5_2/BiasAdd:0' shape=(?, ?, ?, 256) dtype=float32>,\n",
              " <tf.Tensor 'P6_2/BiasAdd:0' shape=(?, ?, ?, 256) dtype=float32>,\n",
              " <tf.Tensor 'P7_2/BiasAdd:0' shape=(?, ?, ?, 256) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "b57X6kWl1IOG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#####Subnet_model = Regression + Classification Model"
      ]
    },
    {
      "metadata": {
        "id": "wHazywfu1I2u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def regression(pyramid_network_filters, regression_filter,num_anchors):\n",
        "  feature_map=     Input(shape =(None,None,pyramid_network_filters))\n",
        "  \n",
        "  Reg1=            Conv2D( kernel_size=3,   filters=regression_filter,   strides=1,   padding='same', activation='relu' ,data_format=data_format, \n",
        "                         kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None), bias_initializer='zeros') (feature_map)\n",
        "  Reg2=            Conv2D( kernel_size=3,   filters=regression_filter,   strides=1,   padding='same', activation='relu' ,data_format=data_format,\n",
        "                         kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None), bias_initializer='zeros') (Reg1)\n",
        "  Reg3=            Conv2D( kernel_size=3,   filters=regression_filter,   strides=1,   padding='same', activation='relu' ,data_format=data_format,\n",
        "                         kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None), bias_initializer='zeros') (Reg2)\n",
        "  Reg4=            Conv2D( kernel_size=3,   filters=regression_filter,   strides=1,   padding='same', activation='relu' ,data_format=data_format,\n",
        "                         kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None), bias_initializer='zeros') (Reg3)\n",
        "  \n",
        "  Reg_subnet_out=  Conv2D( kernel_size=3,   filters= 4 *num_anchors ,   strides=1,   padding='same',   data_format=data_format,\n",
        "                         kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None), bias_initializer='zeros',name='regression_output') (Reg4)\n",
        "  \n",
        "  #Covert Shape=[Batch, W,H, 4*num_anchors] --> [Batch,Anchors,4]\n",
        "  #4D to 3D shape\n",
        "  Reg_subnet_out=  Reshape((-1, 4), name='Regression_reshape') (Reg_subnet_out) \n",
        "  \n",
        "  return keras.models.Model(inputs=feature_map,outputs=Reg_subnet_out,name='Regression_subnet') #[Batch,Anchors,4]\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c9qruOeONwA6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classification(pyramid_network_filters, num_classes,classification_filter,num_anchors):\n",
        "  \n",
        "  bias_init =        - math.log((1 - prior_prob) / prior_prob)     #b = − log((1 − π)/π)\n",
        "  \n",
        "  feature_map =      Input(shape =(None,None,pyramid_network_filters))\n",
        "  \n",
        "  class1=            Conv2D( kernel_size=3,   filters=classification_filter,   strides=1,   padding='same', activation='relu' ,data_format=data_format,\n",
        "                           kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None), bias_initializer='zeros') (feature_map)\n",
        "  class2=            Conv2D( kernel_size=3,   filters=classification_filter,   strides=1,   padding='same', activation='relu' ,data_format=data_format,\n",
        "                           kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None), bias_initializer='zeros') (class1)\n",
        "  class3=            Conv2D( kernel_size=3,   filters=classification_filter,   strides=1,   padding='same', activation='relu' ,data_format=data_format,\n",
        "                           kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None), bias_initializer='zeros') (class2)\n",
        "  class4=            Conv2D( kernel_size=3,   filters=classification_filter,   strides=1,   padding='same', activation='relu' ,data_format=data_format,\n",
        "                           kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None), bias_initializer='zeros') (class3)\n",
        "  \n",
        "  class_subnet_out= Conv2D( kernel_size=3,  filters= num_classes*num_anchors ,   strides=1,   padding='same',   data_format=data_format,\n",
        "                          kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None),\n",
        "                          bias_initializer= keras.initializers.Constant(value=bias_init),name='classification_output' )    (class4) \n",
        "  \n",
        "  #Covert Shape=[Batch, W,H, 4*num_classes] --> [Batch,Anchors,num_classes]\n",
        "  #4D to 3D shape\n",
        "  class_subnet_out = Reshape((-1, num_classes), name='classification_reshape')(class_subnet_out)\n",
        "  class_subnet_out = Activation('sigmoid', name='classification_sigmoid')(class_subnet_out)\n",
        "  \n",
        "  return keras.models.Model(inputs=feature_map, outputs=class_subnet_out, name='Classification_subnet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sGywj1bYk5QC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def subnet_models(pyramid_network_filters, num_classes,regression_filter,classification_filter,num_anchors):\n",
        "  return ([regression(pyramid_network_filters, regression_filter,num_anchors),\n",
        "       classification(pyramid_network_filters, num_classes,regression_filter,num_anchors)]\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KxBx9yYXuxBm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "######Sub-level testing of subnet_models"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8pLvonAuoW_9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sub1= subnet_models(pyramid_network_filters, num_classes,regression_filter,classification_filter,num_anchors)\n",
        "\n",
        "# for M1 in sub1:\n",
        "#   print (\"\\n\",  M1 , \"\\n\" + \"\\n\")\n",
        "#   M1.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4n8u2O2dI21S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Retinanet Model"
      ]
    },
    {
      "metadata": {
        "id": "qcuTEd5Yq-23",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def retinanet_model(input_image_size,include_top, pyramid_network_filters,num_classes,regression_filter,classification_filter,num_anchors):\n",
        "  \n",
        "  # Resnet50 model with trainable50 as backbone layers   \n",
        "  x = keras.layers.Input(input_image_size)\n",
        "  resnet50 = keras_resnet.models.ResNet50(x, classes=num_classes,include_top=include_top)\n",
        "  \n",
        "  for layer in resnet50.layers:\n",
        "    layer.trainable=Resnet_trainable\n",
        "    \n",
        "  print(\"Trainable:-\",resnet50.layers[1].trainable)\n",
        "\n",
        "  backbone_layers= resnet50.outputs[1:]\n",
        "  print (\"\\n backbone_Layers[C3-C5]:-\",backbone_layers)\n",
        "  \n",
        "  #Feature pyramid networks with Resnet backbone (Features)\n",
        "  features = Feature_Pyramid_Network(backbone_layers=backbone_layers, pyramid_network_filters=pyramid_network_filters) # Features [P3,P4,P5,P6,P7]\n",
        "  \n",
        "  #connect subnet to each feature pyramid layer/map\n",
        "  models=subnet_models(pyramid_network_filters, num_classes,regression_filter,classification_filter,num_anchors)\n",
        "  \n",
        "  regression     = keras.layers.Concatenate(axis=1,name='Subnets_Regression')    ([models[0](feature) for feature in features]) #model[0] = regression_model\n",
        "  classification = keras.layers.Concatenate(axis=1,name='Subnets_Classification')([models[1](feature) for feature in features]) #model[1] = classfication_model\n",
        "  \n",
        "  return keras.models.Model(inputs=x, outputs=[regression,classification],name='Retinanet')\n",
        "  \n",
        "  #models = subnet_models(pyramid_network_filters, num_classes,regression_filter,classification_filter,num_anchors)\n",
        "  #Final Retinanet model(Connect subnet to each feature pyramid layer)   \n",
        "  #return keras.layers.Concatenate(axis=1) ([subnet_models(feature_map, num_classes,regression_filter,classification_filter,num_anchors) ]   for feature_map in features) \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "03OWe_b1KAvN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "retinanet = retinanet_model(input_image_size,include_top, pyramid_network_filters,num_classes,regression_filter,classification_filter,num_anchors)\n",
        "retinanet.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tGa8kGwPvnLa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "######Sub-level testing of Retinanet Model"
      ]
    },
    {
      "metadata": {
        "id": "1d62jpBu7KOK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#s = input_image_size\n",
        "#my=keras.models.Model( inputs=[None,None,3], outputs= retinanet_model([None,None,3],include_top,pyramid_network_filters,num_classes,regression_filter,classification_filter,num_anchors) )\n",
        "#my_summary()\n",
        "#backbone_layers=resnet50_model(input_image_size,num_classes,include_top)\n",
        "#t=  retinanet_model(input_image_size,include_top, pyramid_network_filters,num_classes,regression_filter,classification_filter,num_anchors)\n",
        "#t.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ya6Jhl891Nsb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Retinanet box(Wrapper of Retinanet for object detection)"
      ]
    },
    {
      "metadata": {
        "id": "MsX5CicYveYN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#####Generate Anchors"
      ]
    },
    {
      "metadata": {
        "id": "rLvYt4XocmZJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def basic_anchor(size,ratios,scales,num_anchors):\n",
        "  # Generate basic anchors(=num_anchors) based on ratio+scales for each SIZE\n",
        "  \n",
        "  #scaled height & Width\n",
        "  scaled_size= np.array([size * scale for scale in scales])\n",
        "  \n",
        "  heights = scaled_size\n",
        "  widths  = scaled_size\n",
        "  \n",
        "  \n",
        "  #Apply ratio on H & W  \n",
        "  heights = np.array( [ heights*np.sqrt(ratio)   for ratio in ratios] ) # H = H * 1/sqrt(ratio)\n",
        "  widths = np.array( [  widths*np.sqrt(1/ratio)  for ratio in ratios] )  # W = W * sqrt(ratio)\n",
        "   \n",
        "  \n",
        "  heights= np.reshape(heights,(num_anchors) ) #shape=(num_anchors,)\n",
        "  widths = np.reshape(widths, (num_anchors) )\n",
        "  # convert (x,y,h,w) to (x1,y1,x2,y2)  \n",
        "  x1= -(widths)/2\n",
        "  x2= widths/2\n",
        "  y1= -(heights)/2\n",
        "  y2= heights/2\n",
        "  \n",
        "  basic_anchors=np.transpose(np.array([x1,y1,x2,y2]))   # (4,num_anchors)-->(num_anchors,4)\n",
        "  return basic_anchors #(x1,y1,x2,y2) , shape=(num_anchors,4) \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JhUb_pj8gfck",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def shifted_anchor(basic_anchors,num_anchors,feature,stride):  \n",
        "  \n",
        "  import tensorflow\n",
        "  \n",
        "  height_feature = K.shape(feature)[0]\n",
        "  width_feature  = K.shape(feature)[1]\n",
        "  \n",
        "   \n",
        "  shift_y = (K.arange(0, height_feature, dtype=K.floatx()) + K.constant(0.5, dtype=K.floatx())) * stride\n",
        "  shift_x = (K.arange(0, width_feature,  dtype=K.floatx()) + K.constant(0.5, dtype=K.floatx())) * stride\n",
        "\n",
        "  shift_x, shift_y = tf.meshgrid(shift_x, shift_y) # shape=(W_f , H_f) \n",
        "  shift_x = K.reshape(shift_x, [-1]) # shape= W_f * H_f  \n",
        "  shift_y = K.reshape(shift_y, [-1]) \n",
        "  \n",
        " \n",
        "  shifts = K.stack([shift_x,shift_y,shift_x,shift_y], axis=0)   #packed along axis=0 , shape=[4, W_f * H_f ]\n",
        "\n",
        "  shifts            = K.transpose(shifts) #shape=[ W_f * H_f  ,4 ]\n",
        "\n",
        "  pixel_num = K.shape(shifts)[0]  # Total pixel ,K = W_f * H_f\n",
        "  \n",
        "  #Objective apply basic anchors on each pixel/point of feature map\n",
        "  # [1,9,4] + [pixel,1,4] -> [pixel_num ,9,4] -> [pixel_num *9,4]   assuming 9=No. of basic anchors             \n",
        "  shifted_anchor = K.reshape(basic_anchors, [1, num_anchors, 4]) + K.cast(K.reshape(shifts, [pixel_num, 1, 4]), K.floatx())\n",
        "  shifted_anchor = K.reshape(shifted_anchor, [pixel_num * num_anchors, 4])\n",
        "  \n",
        "  return shifted_anchor # shape = [pixel_num *9,4]\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8eEkNYTHO1v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def feature_anchors(feature,size,stride,ratios,scales,num_anchors):\n",
        "  basic_anchors= keras.backend.variable(  basic_anchor(size,ratios,scales,num_anchors))\n",
        "  shifted_anchors= shifted_anchor(basic_anchors,num_anchors,feature,stride) #shape = [pixel_num *9,4] = [shifted_anchor,4 ]   9=basic anchors\n",
        "  shifted_anchors= K.tile(  K.expand_dims(shifted_anchors,axis=0) , (K.shape(feature)[0],1,1) )# Add Batch_size factor\n",
        "  return shifted_anchors #shape = [batch, shifted_anchor, 4]\n",
        "\n",
        "def generate_anchors(features,sizes,strides,ratios,scales,num_anchors):\n",
        "  anchors= [feature_anchors(feature,sizes[i],strides[i],ratios,scales,num_anchors) for i,feature in enumerate (features) ] #shape=[batch,feature_num,shited_anchors,4]\n",
        "  return keras.layers.Concatenate(axis=1, name='anchors')(anchors) #shape=[batch, feature_num*shited_anchors ,4] = [batch, Anchors, 4]\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yDohK0XxvnHv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#####Regression & Clip Boxes"
      ]
    },
    {
      "metadata": {
        "id": "DtltP-PqvzfV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def regressionbox(anchors,deltas):\n",
        "  \n",
        "  #deltas factor of width & height\n",
        "  \n",
        "  width = anchors[:,:,2] - anchors[:,:,0]  # W = x2 - x1\n",
        "  height= anchors[:,:,3] - anchors[:,:,1]  # H = y2 - y1\n",
        "  \n",
        "# 'Tensor' object does not support item assignment, So build list & stack\n",
        "#   anchors[:,:,0]=anchors[:,:,0] + width  * deltas[:,:,0]\n",
        "#   anchors[:,:,1]=anchors[:,:,1] + height * deltas[:,:,1]  \n",
        "#   anchors[:,:,2]=anchors[:,:,2] + width  * deltas[:,:,2]\n",
        "#   anchors[:,:,3]=anchors[:,:,3] + height * deltas[:,:,3]\n",
        "  \n",
        "  #shape(batch,Anchors)\n",
        "  x1=anchors[:,:,0] + width  * deltas[:,:,0]\n",
        "  y1=anchors[:,:,1] + height * deltas[:,:,1]  \n",
        "  x2=anchors[:,:,2] + width  * deltas[:,:,2]\n",
        "  y2=anchors[:,:,3] + height * deltas[:,:,3]\n",
        "  \n",
        "  predicted_boxes = K.stack([x1,y1,x2,y2],axis=2) #shape=(batch,Anchors,4)  \n",
        "  \n",
        "  return predicted_boxes\n",
        "\n",
        "\n",
        "\n",
        "def clipbox(boxes,image):\n",
        "  #clipped box/pixel value which is lying outside input image\n",
        "  image_shape= keras.backend.cast(keras.backend.shape(image), keras.backend.floatx())\n",
        "  height_max = image_shape[0]\n",
        "  width_max  = image_shape[1]\n",
        "  \n",
        "  #shape(batch,Anchors)\n",
        "  x1 = tf.clip_by_value(boxes[:, :, 0], clip_value_min=0, clip_value_max=width_max )\n",
        "  y1 = tf.clip_by_value(boxes[:, :, 1], clip_value_min=0, clip_value_max=height_max)\n",
        "  x2 = tf.clip_by_value(boxes[:, :, 2], clip_value_min=0, clip_value_max=width_max )\n",
        "  y2 = tf.clip_by_value(boxes[:, :, 3], clip_value_min=0, clip_value_max=height_max)\n",
        "  \n",
        "  predicated_cliped_boxes= K.stack([x1,y1,x2,y2],axis=2) #shape=(batch,Anchors,4) \n",
        "  \n",
        "  return predicated_cliped_boxes\n",
        "  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O0SXBJeW8QAp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#####Filter Detection"
      ]
    },
    {
      "metadata": {
        "id": "VGNhDJqE8Xzm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def nms_n_score_threshold(boxes, scores, labels, max_detections, score_threshold, iou_threshold):\n",
        "  #Return indices contain indexes of Anchors after score_threshold+nms \n",
        "  \n",
        "   \n",
        "  #Apply score_threshold + nms\n",
        "  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "  indices = tf.where(K.greater(scores,score_threshold)) #shape=[X,1], X=Not fixed=Reduced_anchors; give index value for (scores>threshold) e.g. [[1][2][3]]  X=True elements\n",
        "  \n",
        "  filtered_boxes=tf.gather_nd(boxes,indices) #shape=[X,4]        # Reason to use gather_nd:-If we use gather here shape[X,1,4]\n",
        "  filtered_scores=K.gather(scores,indices)[:,0]#shape=[X,1] --> [X]  #Reduced_anchors=Anchors whoes score > score_threshold\n",
        "  \n",
        "  #nms: shape=[M] ; M=Seleted Anchores/Tensors (M <= max_output_size)\n",
        "  nms_indices=tf.image.non_max_suppression(boxes=filtered_boxes, scores=filtered_scores, max_output_size=max_detections, iou_threshold=iou_threshold) #e.g. o/p=[1 10 3]\n",
        "  \n",
        "  indices = K.gather(indices,nms_indices) #[M,1]\n",
        "  labels = tf.gather_nd(labels, indices) #[M]\n",
        "  indices_labels = keras.backend.stack([indices[:, 0], labels], axis=1)#shape=[M,2]\n",
        "  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "  return indices_labels "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "--OTta5w_Zhr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def detections_logic(boxes,classification,class_specific_filter=class_specific_filter,max_detections=max_detections,score_threshold=score_threshold,iou_threshold=iou_threshold):\n",
        "  max_detections=10\n",
        "#class_specific_filter=class_specific_filter,max_detections=max_detections,score_threshold=score_threshold,iou_threshold=iou_threshold):\n",
        "#   boxes=args[0]\n",
        "#   classification=args[1]\n",
        "\n",
        "\n",
        "  #~~~~~~~~~nms/score_threshold based on per class based or best scoring class\n",
        "  if class_specific_filter: #classification=[Anchors,num_class]\n",
        "        all_indices = []\n",
        "        # perform per class filtering\n",
        "        for c in range(int(classification.shape[1])):\n",
        "            scores = classification[:, c] #shape=[some_anchors]\n",
        "            labels = c * backend.ones((keras.backend.shape(scores)[0],), dtype='int64') #shape=[some_anchors]\n",
        "            all_indices.append(nms_n_score_threshold(boxes, scores, labels,max_detections,score_threshold,iou_threshold))\n",
        "\n",
        "        # concatenate indices to single tensor\n",
        "        indices_labels = k.concatenate(all_indices, axis=0)#[X,2] X>M\n",
        "  else:\n",
        "    scores        = K.max   (classification,axis=1) #shape=[some_anchors]\n",
        "    labels        = K.argmax(classification,axis=1) #shape=[some_anchors]\n",
        "    indices_labels= nms_n_score_threshold(boxes, scores, labels,max_detections,score_threshold,iou_threshold) #shape=[M,1]\n",
        "    \n",
        "    \n",
        "    # Select Top k(max_detection)\n",
        "    labels              = indices_labels[:, 1] #[X] or [M]\n",
        "    scores   = tf.gather_nd(classification, indices_labels)#[X] or [M]   #shape=[X] for class_specific_filter=TRUE\n",
        "                                                                         #shape=[M] for class_specific_filter=FALSE\n",
        "      \n",
        "    scores_k, top_indices = tf.nn.top_k(input=scores, k=K.minimum(max_detections, K.shape(scores)[0])) #score=Rank 1, k= Rank 0  Tensor; top_k return value+indices\n",
        "    #scores/top_indices = shape[k]\n",
        "    \n",
        "    # filter input using the final set of indices\n",
        "    \n",
        "    indices_k             = keras.backend.gather(indices_labels[:, 0], top_indices)#[K]\n",
        "    boxes_k               = keras.backend.gather(boxes, indices_k)  #[K,4]   Where K <= Max_detection\n",
        "    labels_k              = keras.backend.gather(labels, top_indices) #[K]\n",
        "    \n",
        "    # Zero pad at last rows\n",
        "    pad_size = keras.backend.maximum(0, max_detections - K.shape(scores)[0])#PaddingSize= 0 or max_detection-K\n",
        "    boxes    = tf.pad(boxes_k, [[0, pad_size], [0, 0]], constant_values=-1) #shape[max_detections,4]\n",
        "    scores   = tf.pad(scores_k, [[0, pad_size]], constant_values=-1) #shape[max_detections]\n",
        "    labels   = tf.pad(labels_k, [[0, pad_size]], constant_values=-1) #shape[max_detections]\n",
        "    \n",
        "    labels   = keras.backend.cast(labels, 'int32')\n",
        "    boxes    = keras.backend.cast(boxes, keras.backend.floatx())\n",
        "    scores   = keras.backend.cast(scores,keras.backend.floatx())\n",
        "    \n",
        "    #Verify Shape\n",
        "    \n",
        "    boxes.set_shape([max_detections, 4])\n",
        "    scores.set_shape([max_detections])\n",
        "    labels.set_shape([max_detections])\n",
        "    \n",
        "    return [boxes, scores, labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YCCNduZm_mGn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def filter_detection(boxes,classification,class_specific_filter,max_detections,score_threshold,iou_threshold,parallel_iterations):\n",
        "  \n",
        "  def _detections_logic(args):\n",
        "    return keras.layers.Lambda(lambda detections:detections_logic(boxes=args[0],classification=args[1],class_specific_filter=class_specific_filter,max_detections=max_detections,score_threshold=score_threshold,iou_threshold=iou_threshold))\n",
        "    \n",
        "  #Call detection logic on each batch\n",
        "                            \n",
        "                            \n",
        "  outputs = tf.map_fn(_detections_logic,elems=[boxes,classification],\n",
        "                      #dtype=[keras.backend.floatx(), keras.backend.floatx(),'int32'],\n",
        "                      parallel_iterations=parallel_iterations )\n",
        "  #dtype have 3 types for outputs of detections_logic ([boxes, scores, labels])\n",
        "  print(\"hello\")\n",
        "  print(outputs)\n",
        "  return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UktXZk5H_m2p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "######function Testing"
      ]
    },
    {
      "metadata": {
        "id": "04fRQ0lX_rXG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# data_np=np.array([[1,2,3,1],[1,2,3,4],[7,8,9,1],[20,21,22,1]]) #A=4X3\n",
        "# hp=np.array([[10,20,30],[40,50,60],[70,80,90],[100,110,120]])\n",
        "# data_tf1=data_np[0]\n",
        "# score=np.amax(data_np,axis=1)\n",
        "# score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# score_threshold =tf.constant(3.0)\n",
        "# max_detections = tf.constant(10)\n",
        "# iou_threshold=tf.constant(0.2)\n",
        "# data_tf = tf.convert_to_tensor(data_np, np.float32 )\n",
        "# scores = tf.convert_to_tensor(score, np.float32 )\n",
        "# sc = tf.shape(scores)\n",
        "\n",
        "# Cond  = tf.greater(scores, score_threshold)\n",
        "# indices = tf.where(Cond)\n",
        "# ind= tf.shape(indices)\n",
        "\n",
        "\n",
        "# filtered_boxes  = tf.gather_nd(data_tf, indices)\n",
        "# shape_filtered_boxes = tf.shape(filtered_boxes)[0]\n",
        "\n",
        "# filtered_scores = tf.gather_nd(scores, indices)\n",
        "# shape_filtered_scores = tf.shape(filtered_scores)\n",
        "\n",
        "\n",
        "\n",
        "# g4  = tf.keras.backend.max(data_tf, axis    = 1)\n",
        "# g5  = tf.keras.backend.argmax(data_tf, axis = 1)\n",
        "# g4_shape = tf.shape(g4)\n",
        "\n",
        "# nms_indices=tf.image.non_max_suppression(boxes=data_tf, scores=scores, max_output_size=max_detections, iou_threshold=iou_threshold)\n",
        "# shape_nms=tf.shape(nms_indices)\n",
        "\n",
        "# new = tf.gather(indices, nms_indices)\n",
        "\n",
        "# f1=(data_tf[:,0])\n",
        "# sc, top_indices = tf.nn.top_k(input=f1, k=tf.constant(2))\n",
        "# D=tf.shape(top_indices)\n",
        "# sess = tf.InteractiveSession() \n",
        "# print(data_tf.eval())\n",
        "# print(scores.eval())\n",
        "# print(Cond.eval())\n",
        "# print(indices.eval())\n",
        "# print(ind.eval())\n",
        "# # print(filtered_boxes.eval())\n",
        "# # print(filtered_scores.eval())\n",
        "# # print(shape_filtered_scores.eval())\n",
        "# # print(shape_filtered_boxes.eval())\n",
        "# # print(new.eval())\n",
        "# # print(g4.eval())\n",
        "# # print(g5.eval())\n",
        "# # print(g4_shape.eval())\n",
        "\n",
        "# # print(nms_indices.eval())\n",
        "# # print(shape_nms.eval())\n",
        "\n",
        "# # print(filtered_scores.eval())\n",
        "# # print(top_indices.eval())\n",
        "# # print(f1.eval())\n",
        "# # print(sc.eval())\n",
        "# # print(D.eval())\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "d33d0502-9a69-4fd5-f530-6ff9bd2f91b4",
        "id": "B1EeTS9NKAgP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "elems = np.array([1, 2, 3, 4, 5, 6])\n",
        "squares = tf.map_fn(lambda x: x * x, elems)\n",
        "sess = tf.InteractiveSession() \n",
        "print(squares.eval())"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[ 1  4  9 16 25 36]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A9f1hmGVVjlT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Retinanet_Box"
      ]
    },
    {
      "metadata": {
        "id": "8iW4zGqC1o6i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def retinanet_box(model,input_image_size,include_top, pyramid_network_filters,num_classes,\n",
        "                  regression_filter,classification_filter,num_anchors,sizes,ratios,scales,strides,\n",
        "                 class_specific_filter, max_detections,score_threshold,iou_threshold,parallel_iterations):\n",
        "  if model is None:\n",
        "    model = retinanet_model(input_image_size,include_top, pyramid_network_filters,num_classes,regression_filter,classification_filter,num_anchors)\n",
        "  \n",
        "  \n",
        "  features = [model.get_layer(name=map).output for map in ['P3','P4','P5','P6','P7'] ]  #Pyramid feature map\n",
        "  #print(features)\n",
        "  anchors = generate_anchors(features,sizes,strides,ratios,scales,num_anchors) #[batch, Anchors, 4]; Entire anchors for all batch_images, all features, all pixels\n",
        "  #print(anchors.get_shape())\n",
        "  \n",
        "  #Model output \n",
        "  regression    =model.outputs[0]   #Regression output= Return deltas factor of W(for x1,2) , H(for y1,y2); Shape=[batch,Anchors,4]\n",
        "  classification=model.outputs[1]   #shape=[batch,Anchors,num_classes]\n",
        "  print(regression)\n",
        "  \n",
        "  #Apply regression & clipped Anchors\n",
        "  boxes=regressionbox(anchors,regression) #shape of anchors/regression = [batch,Anchors,4] \n",
        "  boxes=clipbox(boxes,model.inputs[0])    #model.input[0]=input/image shape=[W,H,3],  shape=[batch,Anchors,4]\n",
        "  \n",
        "  #Detection\n",
        "  detections = (filter_detection(boxes,classification,class_specific_filter,max_detections,score_threshold,iou_threshold,parallel_iterations))\n",
        "  print((detections))\n",
        "  \n",
        "  return keras.models.Model(inputs=model.inputs, outputs=detections, name='retinanet_box')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3-yrV51WVn4g",
        "colab_type": "code",
        "outputId": "d6f1d0ba-beef-4b7b-db3a-c848a7e11fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1730
        }
      },
      "cell_type": "code",
      "source": [
        "M=retinanet_box(retinanet,[600,600,3],include_top, pyramid_network_filters,num_classes,regression_filter,classification_filter,num_anchors,sizes,ratios,scales,strides,\n",
        "                 class_specific_filter, max_detections,score_threshold,iou_threshold,parallel_iterations)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Subnets_Regression_3/concat:0\", shape=(?, ?, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36massert_same_structure\u001b[0;34m(nest1, nest2, check_types)\u001b[0m\n\u001b[1;32m    178\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAssertSameStructure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnest2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=list str=[tf.float32, tf.float32]\n\nSecond structure: type=Lambda str=<keras.layers.core.Lambda object at 0x7fa16d25b3c8>\n\nMore specifically: Substructure \"type=list str=[tf.float32, tf.float32]\" is a sequence, while substructure \"type=Lambda str=<keras.layers.core.Lambda object at 0x7fa16d25b3c8>\" is not",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-168-60398c52ec95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m M=retinanet_box(retinanet,[600,600,3],include_top, pyramid_network_filters,num_classes,regression_filter,classification_filter,num_anchors,sizes,ratios,scales,strides,\n\u001b[0;32m----> 2\u001b[0;31m                  class_specific_filter, max_detections,score_threshold,iou_threshold,parallel_iterations)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-167-f56e52066686>\u001b[0m in \u001b[0;36mretinanet_box\u001b[0;34m(model, input_image_size, include_top, pyramid_network_filters, num_classes, regression_filter, classification_filter, num_anchors, sizes, ratios, scales, strides, class_specific_filter, max_detections, score_threshold, iou_threshold, parallel_iterations)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;31m#Detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilter_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_specific_filter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_detections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miou_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-165-41d9013736a6>\u001b[0m in \u001b[0;36mfilter_detection\u001b[0;34m(boxes, classification, class_specific_filter, max_detections, score_threshold, iou_threshold, parallel_iterations)\u001b[0m\n\u001b[1;32m      9\u001b[0m   outputs = tf.map_fn(_detections_logic,elems=[boxes,classification],\n\u001b[1;32m     10\u001b[0m                       \u001b[0;31m#dtype=[keras.backend.floatx(), keras.backend.floatx(),'int32'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                       parallel_iterations=parallel_iterations )\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0;31m#dtype have 3 types for outputs of detections_logic ([boxes, scores, labels])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hello\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0mback_prop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         maximum_iterations=n)\n\u001b[0m\u001b[1;32m    495\u001b[0m     \u001b[0mresults_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3289\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3290\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 3291\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   3292\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3293\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   3002\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 3004\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   3005\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2937\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[1;32m   2938\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2939\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2940\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3258\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3259\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3260\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(i, tas)\u001b[0m\n\u001b[1;32m    482\u001b[0m       \u001b[0mpacked_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_ta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem_ta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melems_ta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m       \u001b[0mpacked_fn_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m       \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacked_fn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m       \u001b[0mflat_fn_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_fn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0mtas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_fn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36massert_same_structure\u001b[0;34m(nest1, nest2, check_types)\u001b[0m\n\u001b[1;32m    184\u001b[0m                   \u001b[0;34m\"Entire first structure:\\n%s\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                   \u001b[0;34m\"Entire second structure:\\n%s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                   % (str(e), str1, str2))\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=list str=[tf.float32, tf.float32]\n\nSecond structure: type=Lambda str=<keras.layers.core.Lambda object at 0x7fa16d25b3c8>\n\nMore specifically: Substructure \"type=list str=[tf.float32, tf.float32]\" is a sequence, while substructure \"type=Lambda str=<keras.layers.core.Lambda object at 0x7fa16d25b3c8>\" is not\nEntire first structure:\n[., .]\nEntire second structure:\n."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ngMHmX8GaXBe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "retinanet.inputs[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "IKfEoZjBKA9u"
      },
      "cell_type": "markdown",
      "source": [
        "## Training "
      ]
    },
    {
      "metadata": {
        "id": "-8AgAnoChJ_5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Focal Loss\n",
        "\n",
        "FL = -α \\* (1-p) ^γ \\ *  log (p)   if y=1\n",
        "\n",
        "FL = -(1-α) \\* p^γ\\  *   log(1-p)  if y=0\n",
        "\n",
        "**General Form of focal loss**\n",
        "\n",
        "Loss = (alpha \\* focal_weight \\* Binary_crossentropy(Y,P))\n",
        "\n",
        "FL = Loss/ Normalization \n",
        "\n",
        "Where: Y=Ytrue P=Ypred\n",
        "\n",
        "Binary_crossentropy(Y,P) = −(Ylog(p)+(1−Y)log(1−p))\n",
        "\n",
        "Y | alpha | focal weight\n",
        "--- | ---\n",
        "0| (1-α) | p^γ\n",
        "1| α | (1-p) ^γ"
      ]
    },
    {
      "metadata": {
        "id": "gg-deu1fMT-C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def focal(alpha=0.25, gamma=2.0):\n",
        "    \"\"\" Create a functor for computing the focal loss.\n",
        "    Args\n",
        "        alpha: Scale the focal weight with alpha.\n",
        "        gamma: Take the power of the focal weight with gamma.\n",
        "    Returns\n",
        "        A functor that computes the focal loss using the alpha and gamma.\n",
        "    \"\"\"\n",
        "    def _focal(y_true, y_pred):\n",
        "        \"\"\" Compute the focal loss given the target tensor and the predicted tensor.\n",
        "        As defined in https://arxiv.org/abs/1708.02002\n",
        "        Args\n",
        "            y_true: Tensor of target data from the generator with shape (B, N, num_classes).\n",
        "            y_pred: Tensor of predicted data from the network with shape (B, N, num_classes).\n",
        "        Returns\n",
        "            The focal loss of y_pred w.r.t. y_true.\n",
        "        \"\"\"\n",
        "        labels         = y_true[:, :, :-1]\n",
        "        anchor_state   = y_true[:, :, -1]  # -1 for ignore, 0 for background, 1 for object\n",
        "        classification = y_pred\n",
        "\n",
        "        # filter out \"ignore\" anchors\n",
        "        indices        = backend.where(keras.backend.not_equal(anchor_state, -1))\n",
        "        labels         = backend.gather_nd(labels, indices)\n",
        "        classification = backend.gather_nd(classification, indices)\n",
        "\n",
        "        # compute the focal loss\n",
        "        alpha_factor = keras.backend.ones_like(labels) * alpha\n",
        "        alpha_factor = backend.where(keras.backend.equal(labels, 1), alpha_factor, 1 - alpha_factor)\n",
        "        focal_weight = backend.where(keras.backend.equal(labels, 1), 1 - classification, classification)\n",
        "        focal_weight = alpha_factor * focal_weight ** gamma\n",
        "\n",
        "        cls_loss = focal_weight * keras.backend.binary_crossentropy(labels, classification)\n",
        "\n",
        "        # compute the normalizer: the number of positive anchors\n",
        "        normalizer = backend.where(keras.backend.equal(anchor_state, 1))\n",
        "        normalizer = keras.backend.cast(keras.backend.shape(normalizer)[0], keras.backend.floatx())\n",
        "        normalizer = keras.backend.maximum(keras.backend.cast_to_floatx(1.0), normalizer)\n",
        "\n",
        "        return keras.backend.sum(cls_loss) / normalizer\n",
        "\n",
        "    return _focal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zDRNTgCUtxSy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Smooth L1 loss"
      ]
    },
    {
      "metadata": {
        "id": "1Dfe00Bst2X2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def smooth_l1(sigma=3.0):\n",
        "    \"\"\" Create a smooth L1 loss functor.\n",
        "    Args\n",
        "        sigma: This argument defines the point where the loss changes from L2 to L1.\n",
        "    Returns\n",
        "        A functor for computing the smooth L1 loss given target data and predicted data.\n",
        "    \"\"\"\n",
        "    sigma_squared = sigma ** 2\n",
        "\n",
        "    def _smooth_l1(y_true, y_pred):\n",
        "        \"\"\" Compute the smooth L1 loss of y_pred w.r.t. y_true.\n",
        "        Args\n",
        "            y_true: Tensor from the generator of shape (B, N, 5). The last value for each box is the state of the anchor (ignore, negative, positive).\n",
        "            y_pred: Tensor from the network of shape (B, N, 4).\n",
        "        Returns\n",
        "            The smooth L1 loss of y_pred w.r.t. y_true.\n",
        "        \"\"\"\n",
        "        # separate target and state\n",
        "        regression        = y_pred\n",
        "        regression_target = y_true[:, :, :-1]\n",
        "        anchor_state      = y_true[:, :, -1]\n",
        "\n",
        "        # filter out \"ignore\" anchors\n",
        "        indices           = backend.where(keras.backend.equal(anchor_state, 1))\n",
        "        regression        = backend.gather_nd(regression, indices)\n",
        "        regression_target = backend.gather_nd(regression_target, indices)\n",
        "\n",
        "        # compute smooth L1 loss\n",
        "        # f(x) = 0.5 * (sigma * x)^2          if |x| < 1 / sigma / sigma\n",
        "        #        |x| - 0.5 / sigma / sigma    otherwise\n",
        "        regression_diff = regression - regression_target\n",
        "        regression_diff = keras.backend.abs(regression_diff)\n",
        "        regression_loss = backend.where(\n",
        "            keras.backend.less(regression_diff, 1.0 / sigma_squared),\n",
        "            0.5 * sigma_squared * keras.backend.pow(regression_diff, 2),\n",
        "            regression_diff - 0.5 / sigma_squared\n",
        "        )\n",
        "\n",
        "        # compute the normalizer: the number of positive anchors\n",
        "        normalizer = keras.backend.maximum(1, keras.backend.shape(indices)[0])\n",
        "        normalizer = keras.backend.cast(normalizer, dtype=keras.backend.floatx())\n",
        "        return keras.backend.sum(regression_loss) / normalizer\n",
        "\n",
        "    return _smooth_l1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CqycT51_xTyM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Train Model"
      ]
    },
    {
      "metadata": {
        "id": "iwCwdcsAxTQy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Training_model = retinanet_model(input_image_size,include_top, pyramid_network_filters,num_classes,regression_filter,classification_filter,num_anchors)\n",
        "prediction_model = Training_model(retinanet,[600,600,3],include_top, pyramid_network_filters,num_classes,regression_filter,classification_filter,num_anchors,sizes,ratios,scales,strides,\n",
        "                 class_specific_filter, max_detections,score_threshold,iou_threshold,parallel_iterations)\n",
        "\n",
        "# compile model\n",
        "training_model.compile(\n",
        "    loss={\n",
        "        'regression'    : smooth_l1(),\n",
        "        'classification': focal()\n",
        "    },\n",
        "    optimizer=keras.optimizers.adam(lr=lr, clipnorm=0.001)\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}